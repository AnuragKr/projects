{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3871469,"sourceType":"datasetVersion","datasetId":2301194}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Finetuning With Pre-trained Albert Model","metadata":{}},{"cell_type":"code","source":"# Load model directly\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold\n\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nmodel_name = 'textattack/albert-base-v2-imdb'\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-09T18:15:06.111143Z","iopub.execute_input":"2024-06-09T18:15:06.111848Z","iopub.status.idle":"2024-06-09T18:15:06.598831Z","shell.execute_reply.started":"2024-06-09T18:15:06.111814Z","shell.execute_reply":"2024-06-09T18:15:06.598019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = str(self.texts.iloc[idx])\n        label = self.labels.iloc[idx]\n\n        encoding = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            return_token_type_ids=False,\n            padding='max_length',\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt',\n        )\n\n        return {\n            'text': text,\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'label': torch.tensor(label, dtype=torch.long)\n        }","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:15:09.658096Z","iopub.execute_input":"2024-06-09T18:15:09.658809Z","iopub.status.idle":"2024-06-09T18:15:09.666486Z","shell.execute_reply.started":"2024-06-09T18:15:09.658776Z","shell.execute_reply":"2024-06-09T18:15:09.665515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set maximum sequence length\nMAX_LEN = 128","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:15:15.128080Z","iopub.execute_input":"2024-06-09T18:15:15.128748Z","iopub.status.idle":"2024-06-09T18:15:15.132957Z","shell.execute_reply.started":"2024-06-09T18:15:15.128710Z","shell.execute_reply":"2024-06-09T18:15:15.131930Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# configuring path\ndata_path = '../input/amazon-customerreviews-polarity'\ntrain_data_path = data_path + '/train.csv'\ntest_data_path = data_path + '/test.csv'\noutput_path = '../working/'\nmodel_path = output_path + 'model/'\noutput_file_path = output_path + 'file/'\n!mkdir \"$model_path\"\n!mkdir \"$output_file_path\"","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:15:18.853754Z","iopub.execute_input":"2024-06-09T18:15:18.854082Z","iopub.status.idle":"2024-06-09T18:15:20.979486Z","shell.execute_reply.started":"2024-06-09T18:15:18.854058Z","shell.execute_reply":"2024-06-09T18:15:20.978366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data loading\ntrain_df = pd.read_csv(train_data_path)\ntest_df = pd.read_csv(test_data_path)\n\n# column addition\ntrain_df.columns = ['polarity','title','text']\ntest_df.columns = ['polarity','title','text']","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:15:36.310886Z","iopub.execute_input":"2024-06-09T18:15:36.311274Z","iopub.status.idle":"2024-06-09T18:15:58.513059Z","shell.execute_reply.started":"2024-06-09T18:15:36.311239Z","shell.execute_reply":"2024-06-09T18:15:58.512032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to convert score to sentiment\ndef to_sentiment(rating):\n    \n    rating = int(rating)\n    \n    # Convert to class\n    if rating == 1: # negative\n        return 0\n    elif rating == 2: # Positive\n        return 1\n    else:\n        return 3\n\n# Apply to the dataset \ntrain_df['polarity'] = train_df.polarity.apply(to_sentiment)\ntest_df['polarity'] = test_df.polarity.apply(to_sentiment)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:16:14.806976Z","iopub.execute_input":"2024-06-09T18:16:14.807665Z","iopub.status.idle":"2024-06-09T18:16:17.878441Z","shell.execute_reply.started":"2024-06-09T18:16:14.807617Z","shell.execute_reply":"2024-06-09T18:16:17.877413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's check for missing values in train data\nprint('---------Training Data-----------')\nprint(train_df.isnull().sum())\n\n# Let's check for missing values in test data\nprint('---------Test Data-----------')\nprint(test_df.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:16:21.112409Z","iopub.execute_input":"2024-06-09T18:16:21.113282Z","iopub.status.idle":"2024-06-09T18:16:22.027452Z","shell.execute_reply.started":"2024-06-09T18:16:21.113245Z","shell.execute_reply":"2024-06-09T18:16:22.026550Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Substituting Null values with empty spaces\ntrain_df['title'] = train_df['title'].fillna(' ')\ntest_df['title'] = test_df['title'].fillna(' ')\n\n# Let's check for missing values in train data\nprint('---------Training Data-----------')\nprint(train_df.isnull().sum())\n\n# Let's check for missing values in test data\nprint('---------Test Data-----------')\nprint(test_df.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:16:25.940681Z","iopub.execute_input":"2024-06-09T18:16:25.941539Z","iopub.status.idle":"2024-06-09T18:16:27.462616Z","shell.execute_reply.started":"2024-06-09T18:16:25.941503Z","shell.execute_reply":"2024-06-09T18:16:27.461663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['review'] = train_df['title'].astype(str) + ' ' + train_df['text'].astype(str)\ntest_df['review'] = test_df['title'].astype(str) + ' ' + test_df['text'].astype(str)\n\nprint('---------Training Data Shape-----------')\nprint(train_df.shape)\n\nprint('---------Test Data Shape-----------')\nprint(test_df.shape)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:16:30.480591Z","iopub.execute_input":"2024-06-09T18:16:30.481365Z","iopub.status.idle":"2024-06-09T18:16:32.852451Z","shell.execute_reply.started":"2024-06-09T18:16:30.481336Z","shell.execute_reply":"2024-06-09T18:16:32.851537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Randomly sample 1Lac elements from your dataframe\ntrain_df = train_df.sample(n=100000)\ntest_df = test_df.sample(n=10000)\nprint(train_df.shape,train_df.shape)\nprint(test_df.shape,test_df.shape)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:16:37.974275Z","iopub.execute_input":"2024-06-09T18:16:37.975223Z","iopub.status.idle":"2024-06-09T18:16:38.845251Z","shell.execute_reply.started":"2024-06-09T18:16:37.975190Z","shell.execute_reply":"2024-06-09T18:16:38.844127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Separating out independent and dependent columns\nX_train = train_df.drop(['polarity'],axis = 1)\nY_train = train_df.drop(['title','text','review'],axis = 1)\nX_test = test_df.drop(['polarity'],axis = 1)\nY_test = test_df.drop(['title','text','review'],axis = 1)\n\nX_train = X_train.drop(['title','text'],axis = 1)\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.33, random_state=4, stratify=Y_train)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:16:41.590022Z","iopub.execute_input":"2024-06-09T18:16:41.590886Z","iopub.status.idle":"2024-06-09T18:16:41.662092Z","shell.execute_reply.started":"2024-06-09T18:16:41.590852Z","shell.execute_reply":"2024-06-09T18:16:41.661215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create DataLoaders for train and val sets\ntrain_dataset = CustomDataset(X_train['review'], Y_train['polarity'], tokenizer, MAX_LEN)\nval_dataset = CustomDataset(X_val['review'], Y_val['polarity'], tokenizer, MAX_LEN)\ntest_dataset = CustomDataset(X_test['review'], Y_test['polarity'], tokenizer, MAX_LEN)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:16:44.958610Z","iopub.execute_input":"2024-06-09T18:16:44.959028Z","iopub.status.idle":"2024-06-09T18:16:44.966771Z","shell.execute_reply.started":"2024-06-09T18:16:44.958997Z","shell.execute_reply":"2024-06-09T18:16:44.965528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define training parameters\nbatch_size = 32\nepochs = 10\nlr = 2e-5\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:16:55.729248Z","iopub.execute_input":"2024-06-09T18:16:55.729598Z","iopub.status.idle":"2024-06-09T18:16:55.735025Z","shell.execute_reply.started":"2024-06-09T18:16:55.729569Z","shell.execute_reply":"2024-06-09T18:16:55.733997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:16:59.705669Z","iopub.execute_input":"2024-06-09T18:16:59.706039Z","iopub.status.idle":"2024-06-09T18:17:00.420771Z","shell.execute_reply.started":"2024-06-09T18:16:59.706011Z","shell.execute_reply":"2024-06-09T18:17:00.419790Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training loop\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:17:02.998498Z","iopub.execute_input":"2024-06-09T18:17:02.998861Z","iopub.status.idle":"2024-06-09T18:17:03.017520Z","shell.execute_reply.started":"2024-06-09T18:17:02.998834Z","shell.execute_reply":"2024-06-09T18:17:03.016556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Freeze all layers except the classification layer\nfor param in model.parameters():\n    param.requires_grad = False\n\n# Unfreeze the classification layer\nfor param in model.classifier.parameters():\n    param.requires_grad = True","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:17:05.958111Z","iopub.execute_input":"2024-06-09T18:17:05.958458Z","iopub.status.idle":"2024-06-09T18:17:05.963588Z","shell.execute_reply.started":"2024-06-09T18:17:05.958434Z","shell.execute_reply":"2024-06-09T18:17:05.962569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calculate_accuracy(model, loader, device):\n    model.eval()\n    correct, total = 0, 0\n    with torch.no_grad():\n        for batch in loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n\n            outputs = model(input_ids, attention_mask=attention_mask)\n            predictions = torch.argmax(outputs.logits, dim=1)\n            correct += (predictions == labels).sum().item()\n            total += labels.size(0)\n\n    return 100 * correct / total","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:17:09.070472Z","iopub.execute_input":"2024-06-09T18:17:09.071201Z","iopub.status.idle":"2024-06-09T18:17:09.077992Z","shell.execute_reply.started":"2024-06-09T18:17:09.071155Z","shell.execute_reply":"2024-06-09T18:17:09.076995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_val_loss = float('inf')  # Initialize best_val_loss to a very high value\nbest_epoch = -1  # Initialize best_epoch to an invalid value to track the epoch of the best validation loss\n\nprint('---------------Training Started------------')\nfor epoch in range(epochs):\n    model.train()\n    total_train_loss = 0\n    total_val_loss = 0\n\n    # Training\n    for batch in train_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].to(device)\n\n        optimizer.zero_grad()\n        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n\n        total_train_loss += loss.item()\n\n    avg_train_loss = total_train_loss / len(train_loader)\n\n    # Validation\n    model.eval()\n    with torch.no_grad():\n        for batch in val_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n\n            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n            loss = outputs.loss\n            total_val_loss += loss.item()\n\n    avg_val_loss = total_val_loss / len(val_loader)\n\n    # Check if the current validation loss is the lowest; if so, save the model\n    if avg_val_loss < best_val_loss:\n        best_val_loss = avg_val_loss\n        best_epoch = epoch\n        torch.save(model.state_dict(), model_path + 'albert_finetune_best_model.pth')  # Save the best model\n\n    print(f\"Epoch {epoch + 1}/{epochs}, Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")\n\n# Print the best epoch and its validation loss\nprint(f\"The lowest validation loss was {best_val_loss:.4f} at epoch {best_epoch + 1}\")\n\n# Load the best model and calculate accuracy\nmodel.load_state_dict(torch.load(model_path + 'albert_finetune_best_model.pth'))\ntrain_accuracy = calculate_accuracy(model, train_loader, device)\nval_accuracy = calculate_accuracy(model, val_loader, device)\n\nprint(f'Best Model Training Accuracy: {train_accuracy:.2f}%')\nprint(f'Best Model Validation Accuracy: {val_accuracy:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:17:12.464643Z","iopub.execute_input":"2024-06-09T18:17:12.465083Z","iopub.status.idle":"2024-06-09T18:18:04.277565Z","shell.execute_reply.started":"2024-06-09T18:17:12.465048Z","shell.execute_reply":"2024-06-09T18:18:04.276666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load(model_path + 'albert_finetune_best_model.pth'))\ntest_accuracy = calculate_accuracy(model,test_loader, device)\nprint(f'Test Accuracy: {test_accuracy}%')","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:18:15.118691Z","iopub.execute_input":"2024-06-09T18:18:15.119439Z","iopub.status.idle":"2024-06-09T18:18:15.639310Z","shell.execute_reply.started":"2024-06-09T18:18:15.119406Z","shell.execute_reply":"2024-06-09T18:18:15.638373Z"},"trusted":true},"execution_count":null,"outputs":[]}]}